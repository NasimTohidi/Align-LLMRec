import torch
import torch.nn as nn
from transformers import AutoModel

class CrossAttentionFusion(nn.Module):
    def __init__(self, embed_dim):
        super().__init__()
        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads=4)
        
    def forward(self, m_text, m_review):
        # m_text: semantic meta, m_review: affective reviews
        # Query from metadata, Key/Value from reviews for sentiment extraction
        attn_output, _ = self.multihead_attn(m_text, m_review, m_review)
        return attn_output

class AlignLLMRec(nn.Module):
    def __init__(self, item_count, d_model=256):
        super().__init__()
        # CF Backbone: Sequential Transformer
        self.item_embedding = nn.Embedding(item_count, d_model)
        self.cf_encoder = nn.TransformerEncoderLayer(d_model, nhead=4)
        
        # Textual Encoders
        self.sbert_proj = nn.Linear(768, d_model) # SBERT for Metadata
        self.distilbert_proj = nn.Linear(768 + 1, d_model) # DistilBERT + Sentiment for Reviews
        
        # Semantic Fusion
        self.fusion = CrossAttentionFusion(d_model)
        
        # Stage II Projection Interface
        self.llm_proj_u = nn.Sequential(nn.Linear(d_model, 4096), nn.ReLU())
        self.llm_proj_i = nn.Sequential(nn.Linear(d_model, 4096), nn.ReLU())

    def forward_stage1(self, seq, meta_emb, review_emb, sentiment_s):
        # 1. CF Preference
        cf_items = self.item_embedding(seq)
        u_t = self.cf_encoder(cf_items)[:, -1, :] # Final user representation
        
        # 2. Textual Embeddings (Stage I)
        m_T = torch.relu(self.sbert_proj(meta_emb))
        m_R = torch.relu(self.W_R(torch.cat([distilbert_review_emb, sentiment_s], dim=-1)))
        
        # 3. Cross-Attention Fusion
        m_fused = self.fusion(m_T.unsqueeze(0), m_R.unsqueeze(0)).squeeze(0)
        return u_t, cf_items[:, -1, :], m_fused
    
    def construct_soft_prompt(self, text_prompts, u_p, i_p):
        # 1. Get LLM's standard word embeddings for the text parts of the prompt
        # 2. Insert u_p and i_p into the correct positions (as "soft tokens")
        # 3. Return a single tensor of shape [batch, seq_len, 4096]
        pass
